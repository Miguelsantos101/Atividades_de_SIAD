# -*- coding: utf-8 -*-
"""Atividade EAD 1 - SIAD.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KJR4M96OyNg6xMXq-PsEpdfAvbtSiIZN
"""

# Importação das bibliotecas necessárias
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, confusion_matrix
from sklearn.preprocessing import StandardScaler

os.system("cls" if os.name == "nt" else "clear")

# 1. Carregamento dos dados
df = pd.read_csv(os.path.join(os.path.dirname(__file__), "banknote-authentication.csv"))

# 2. Exploração dos dados
print("Valores faltantes por coluna:")
print(df.isnull().sum().to_string())

# Estatísticas descritivas dos dados
print("\nEstatísticas descritivas:")
print(df.describe())

# Visualização da distribuição dos atributos com histogramas
df.hist(figsize=(12,8))
plt.suptitle("Histograma dos atributos")
plt.show()

# 3. Visualização dos dados
classe_col = 'class'
plt.figure(figsize=(8,6))
plt.scatter(df[df[classe_col]==0][df.columns[0]], df[df[classe_col]==0][df.columns[1]], color='blue', label='Autêntico')
plt.scatter(df[df[classe_col]==1][df.columns[0]], df[df[classe_col]==1][df.columns[1]], color='red', label='Falsificado')
plt.xlabel(df.columns[0])
plt.ylabel(df.columns[1])
plt.title("Scatter plot entre {} e {} pela classe".format(df.columns[0], df.columns[1]))
plt.legend()
plt.show()

# 4. Análise inicial do problema
print("\nDimensões do dataset:")
print(df.shape)

print("\nDistribuição da classe:")
print(df[classe_col].value_counts().to_string())

# 5. Construção do modelo de classificação
# Separando os atributos (X) e a variável target (y)
X = df.drop(columns=[classe_col])
y = df[classe_col]

# Dividindo os dados em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Instanciando e treinando o modelo Random Forest
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)

# Validação cruzada com 10 folds
cv_scores = cross_val_score(rf, X, y, cv=10)
print("\nScores da validação cruzada (10 folds):")
print(cv_scores)
print("Média dos scores:", np.mean(cv_scores))

# 6. Avaliação do modelo
# Prevendo no conjunto de teste
y_pred = rf.predict(X_test)

# Cálculo de acurácia e precisão
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
print("\nAcurácia do modelo:", acc)
print("Precisão do modelo:", prec)

# Matriz de confusão
cm = confusion_matrix(y_test, y_pred)
print("\nMatriz de Confusão:")
print(cm)

# 7. Interpretação dos resultados
importances = rf.feature_importances_
indices = np.argsort(importances)[::-1]
print("\nImportância dos atributos:")
for i in range(len(importances)):
    print(f"{X.columns[indices[i]]}: {importances[indices[i]]:.4f}")

# ●  O problema foi resolvido com sucesso?
#    R: Sim, o modelo demonstrou alta acurácia e robustez entre treino e teste.

# ●  Algum atributo teve maior importância para o modelo?
#    R: Sim, o atributo de variância se destacou como crucial para a classificação.

# ●  Os resultados poderiam ser melhorados? Como?
#    R: Sim, melhorias podem ser alcançadas ajustando hiperparâmetros e aprimorando o pré-processamento.

# 8. Reanálise com Normalização
# Aplicando StandardScaler para normalizar os atributos
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Dividindo novamente os dados normalizados em treino e teste
X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

# Treinando o modelo com os dados normalizados
rf_scaled = RandomForestClassifier(random_state=42)
rf_scaled.fit(X_train_scaled, y_train)

# Validação cruzada com 10 folds nos dados normalizados
cv_scores_scaled = cross_val_score(rf_scaled, X_scaled, y, cv=10)
print("\nScores da validação cruzada com dados normalizados (10 folds):")
print(cv_scores_scaled)
print("Média dos scores:", np.mean(cv_scores_scaled))

# Avaliação do modelo com dados normalizados
y_pred_scaled = rf_scaled.predict(X_test_scaled)
acc_scaled = accuracy_score(y_test, y_pred_scaled)
prec_scaled = precision_score(y_test, y_pred_scaled)

print("\nAcurácia do modelo com normalização:", acc_scaled)
print("Precisão do modelo com normalização:", prec_scaled)

cm_scaled = confusion_matrix(y_test, y_pred_scaled)
print("\nMatriz de Confusão com dados normalizados:")
print(cm_scaled)